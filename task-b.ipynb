{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcfab52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-05 16:33:35,085] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khanddorj/Documents/code/ShowUI/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from functools import partial\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import deepspeed\n",
    "\n",
    "from data.dataset import HybridDataset, collate_fn\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from model.showui.processing_showui import ShowUIProcessor\n",
    "from model.showui.modeling_showui import ShowUIForConditionalGeneration\n",
    "from main.eval_screenspot import validate_screenspot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40425d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables BEFORE importing deepspeed\n",
    "os.environ['RANK'] = '0'\n",
    "os.environ['LOCAL_RANK'] = '0'\n",
    "os.environ['WORLD_SIZE'] = '1'\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '9994'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fadc9f",
   "metadata": {},
   "source": [
    "Loading processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88beee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### ShowUI Preprocessor\n",
    "# 0. Common setups\n",
    "min_pixels = 256*28*28\n",
    "max_pixels = 1344*28*28\n",
    "# 1. Screenshot -> Graph\n",
    "uigraph_train = True        # Enable ui graph during training\n",
    "uigraph_test = True         # Enable ui graph during inference\n",
    "uigraph_diff = 1            # Pixel difference used for constructing ui graph\n",
    "uigraph_rand = False        # Enable random graph construction \n",
    "# 2. Graph -> Mask \n",
    "uimask_pre = True           # Prebuild patch selection mask in the preprocessor (not in model layers) for efficiency\n",
    "uimask_ratio = 0.5          # Specify the percentage of patch tokens to skip per component\n",
    "uimask_rand = False         # Enable random token selection instead of uniform selection\n",
    "\n",
    "### ShowUI Model\n",
    "lm_skip_ratio = uimask_ratio # valid if not uimask_pre\n",
    "lm_skip_layer = \"[1,28,1]\"   # [1,28,1] means we apply UI guide token selection from 1-th to 28-th layer (28 is the last layer of Qwen2-VL)\n",
    "\n",
    "processor = ShowUIProcessor.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct\", \n",
    "    min_pixels=min_pixels, max_pixels=max_pixels,\n",
    "    uigraph_train=uigraph_train, uigraph_test=uigraph_test, uigraph_diff=uigraph_diff, uigraph_rand=uigraph_rand,\n",
    "    uimask_pre=True, uimask_ratio=uimask_ratio, uimask_rand=uimask_rand,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b9cc39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:model.showui.modeling_showui:`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "lm_qwen_layer = 28\n",
    "\n",
    "def parse_layer_type(str_ranges, L=lm_qwen_layer, default=0):\n",
    "    # 0 is without layer token selection, 1 is with layer token selection. Below we provide examples:\n",
    "    # [1,28,1] means that all LM layers use token selection; [1,28,0] means that do not.\n",
    "    # Interleaved layer-wise '[2,2,1],[4,4,1],[6,6,1],[8,8,1],[10,10,1],[12,12,1],[14,14,1],[16,16,1],[18,18,1],[20,20,1],[22,22,1],[24,24,1],[26,26,1]'\n",
    "    result = [default] * L\n",
    "    \n",
    "    # Handle None or non-string input\n",
    "    if str_ranges is None or str_ranges == '':\n",
    "        return result\n",
    "    \n",
    "    # Convert to string if not already\n",
    "    if not isinstance(str_ranges, str):\n",
    "        str_ranges = str(str_ranges)\n",
    "    \n",
    "    matches = re.findall(r'\\[\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\]', str_ranges)\n",
    "    for start, end, value in matches:\n",
    "        start, end, value = int(start) - 1, int(end) - 1, int(value)\n",
    "        if 0 <= start < L and 0 <= end < L:\n",
    "            result[start:end + 1] = [value] * (end - start + 1)\n",
    "    return result\n",
    "\n",
    "lm_skip_layer = parse_layer_type(lm_skip_layer, 28)\n",
    "# print(lm_skip_layer)\n",
    "\n",
    "model = ShowUIForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda:0\",\n",
    "    lm_skip_ratio=lm_skip_ratio, lm_skip_layer=lm_skip_layer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65298033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args):\n",
    "    parser = argparse.ArgumentParser(description=\"ShowUI Training Pipeline\")\n",
    "    # Environment\n",
    "    parser.add_argument(\"--wandb_key\", default=None, type=str, help=\"wandb key to monitor training\")\n",
    "    parser.add_argument(\"--local_rank\", default=0, type=int, help=\"node rank\")\n",
    "    parser.add_argument(\n",
    "        \"--precision\",\n",
    "        default=\"bf16\",\n",
    "        type=str,\n",
    "        choices=[\"fp32\", \"bf16\", \"fp16\"],\n",
    "        help=\"precision for inference\",\n",
    "    )\n",
    "    parser.add_argument(\"--ds_zero\", choices=['zero1', 'zero2', 'zero3'], default='zero2', help=\"deepspeed zero stage\")\n",
    "    parser.add_argument(\"--load_in_8bit\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--load_in_4bit\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--attn_imple\", choices=[\"eager\", \"flash_attention_2\", \"sdpa\"], default=\"eager\")\n",
    "    parser.add_argument(\"--liger_kernel\", action=\"store_true\", default=False)\n",
    "\n",
    "    # Model & Ckpt\n",
    "    parser.add_argument(\"--model_id\", default=\"showlab/ShowUI-2B\", choices=[\"showlab/ShowUI-2B\", \"Qwen/Qwen2-VL-2B-Instruct\", \"Qwen/Qwen2-VL-7B-Instruct\", \\\n",
    "                                                                            \"Qwen/Qwen2.5-VL-3B-Instruct\"])\n",
    "    parser.add_argument(\"--version\", default=\"showlab/ShowUI-2B\")\n",
    "    parser.add_argument(\"--max_new_tokens\", default=128, type=int, help=\"max. generated token length\")\n",
    "    parser.add_argument(\"--local_weight\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--local_weight_dir\",  default=\".\", help=\"default path to load the model weight\")\n",
    "    # Visual Encoder Training strategy\n",
    "    parser.add_argument(\"--tune_visual_encoder\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--tune_visual_encoder_projector\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--freeze_lm_embed\", action=\"store_true\", default=False)\n",
    "\n",
    "    # Training / Validation Data\n",
    "    parser.add_argument(\"--dataset_dir\", default=\"./dataset\", type=str)\n",
    "    parser.add_argument(\"--train_dataset\", default=\"showui\", type=str)\n",
    "    parser.add_argument(\"--train_json\", default=\"hf_train\", type=str)\n",
    "    parser.add_argument(\"--train_ratio\", default=\"1\", type=str)\n",
    "    parser.add_argument(\"--val_dataset\", default=\"screenspot\", type=str)\n",
    "    parser.add_argument(\"--val_json\", default=\"hf_test_full\", type=str)\n",
    "    parser.add_argument(\"--val_ratio\", default=\"1\", type=str)\n",
    "    parser.add_argument(\"--uniform_sample\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--random_sample\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--record_sample\", action=\"store_true\", default=False)\n",
    "    \n",
    "    ### ShowUI Preprocessor\n",
    "    # 0. Common setups\n",
    "    parser.add_argument(\"--min_visual_tokens\", default=256, type=int)\n",
    "    parser.add_argument(\"--max_visual_tokens\", default=1280, type=int)\n",
    "    parser.add_argument(\"--model_max_length\", default=8192, type=int)\n",
    "    # 1. Screenshot -> Graph\n",
    "    parser.add_argument(\"--uigraph_train\", action=\"store_false\", default=True, help=\"Enable ui graph during training\")\n",
    "    parser.add_argument(\"--uigraph_test\", action=\"store_true\", default=False, help=\"Enable ui graph during inference\")\n",
    "    parser.add_argument(\"--uigraph_diff\", default=1, type=int, help=\"Pixel difference used for constructing ui graph\")\n",
    "    parser.add_argument(\"--uigraph_rand\", action=\"store_true\", default=False, help=\"Enable random graph construction\")\n",
    "    # 2. Graph -> Mask \n",
    "    parser.add_argument(\"--uimask_pre\", action=\"store_false\", default=True, help=\"Prebuild patch selection mask in the preprocessor (not in model layers) for efficiency\")\n",
    "    parser.add_argument(\"--uimask_ratio\", default=0.5, type=float, help=\"Specify the percentage of patch tokens to skip per component\")\n",
    "    parser.add_argument(\"--uimask_rand\", action=\"store_true\", default=False, help=\"Enable random token selection instead of uniform selection\")\n",
    "    ### ShowUI Model\n",
    "    # 0 is without layer token selection, 1 is with layer token selection. Below we provide examples:\n",
    "    # [1,28,1] means that all LM layers use token selection; [1,28,0] means that do not.\n",
    "    # Interleaved layer-wise '[2,2,1],[4,4,1],[6,6,1],[8,8,1],[10,10,1],[12,12,1],[14,14,1],[16,16,1],[18,18,1],[20,20,1],[22,22,1],[24,24,1],[26,26,1]'\n",
    "    parser.add_argument(\"--lm_skip_ratio\", default=0, type=float)\n",
    "    parser.add_argument(\"--lm_skip_layer\", default='[1,28,0]', type=str)\n",
    "    parser.add_argument(\"--vis_skip_ratio\", default=0, type=float)\n",
    "    parser.add_argument(\"--vis_skip_layer\", default='[1,32,0]', type=str)\n",
    "    # Pretrain / Supervised Fine-tuning\n",
    "    parser.add_argument(\"--showui_data\", default=\"hf_train\", type=str)\n",
    "    parser.add_argument(\"--amex_data\", default=\"hf_train\", type=str)\n",
    "    parser.add_argument(\"--guiact_data\", default=\"hf_train_web-single_v2\", type=str)\n",
    "    parser.add_argument(\"--ricosca_data\", default=\"hf_train_ricosca\", type=str)\n",
    "    parser.add_argument(\"--widget_data\", default=\"hf_train_widget\", type=str)\n",
    "    parser.add_argument(\"--screencap_data\", default=\"hf_train_screencap\", type=str)\n",
    "    # Downstream train. set\n",
    "    parser.add_argument(\"--aitw_data\", default=\"hf_train\", type=str)\n",
    "    parser.add_argument(\"--mind2web_data\", default=\"hf_train\", type=str)\n",
    "    parser.add_argument(\"--miniwob_data\", default=\"hf_train\", type=str)\n",
    "    # Downstream val. set\n",
    "    parser.add_argument(\"--val_aitw_data\", default=\"hf_test\", type=str)\n",
    "    parser.add_argument(\"--val_mind2web_data\", default=\"hf_test_full\", type=str)\n",
    "    parser.add_argument(\"--val_screenspot_data\", default=\"hf_test_full\", type=str)\n",
    "\n",
    "    # Grounding setting\n",
    "    parser.add_argument(\"--num_turn\", default=1, type=int, help=\"Interleaved Query-Action setting\")\n",
    "    parser.add_argument(\"--shuffle_image_token\", action=\"store_true\", default=False, help=\"shuffle image token for training\")\n",
    "    parser.add_argument(\"--uniform_prompt\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--text2point\", default=1, type=float)\n",
    "    parser.add_argument(\"--text2bbox\", default=0, type=float)\n",
    "    parser.add_argument(\"--point2text\", default=0, type=float)\n",
    "    parser.add_argument(\"--bbox2text\", default=0, type=float)\n",
    "    parser.add_argument(\"--crop_min\", default=1, type=float)\n",
    "    parser.add_argument(\"--crop_max\", default=1, type=float)\n",
    "    parser.add_argument(\"--xy_int\", action=\"store_true\", default=False)\n",
    "\n",
    "    # Navigation setting\n",
    "    parser.add_argument(\"--num_history\", default=4, type=int)\n",
    "    parser.add_argument(\"--interleaved_history\", default='tttt',  choices=['tttt', 'vvvv', 'vtvt', 'tvtv', 'vvtt', 'ttvv'], help=\"Interleaved Vision-Action setting\")\n",
    "    parser.add_argument(\"--skip_readme_train\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--skip_readme_test\", action=\"store_true\", default=False)\n",
    "\n",
    "    # Lora\n",
    "    parser.add_argument(\"--use_qlora\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--lora_r\", default=8, type=int)\n",
    "    parser.add_argument(\"--lora_alpha\", default=16, type=int)\n",
    "    parser.add_argument(\"--lora_dropout\", default=0.05, type=float)\n",
    "    parser.add_argument(\"--lora_target_modules\", default=\"qkv_proj\", type=str)\n",
    "\n",
    "    # Training\n",
    "    parser.add_argument(\"--log_base_dir\", default=\"../runs\", type=str)\n",
    "    parser.add_argument(\"--exp_id\", default=\"debug\", type=str)\n",
    "    parser.add_argument(\"--workers\", default=16, type=int)\n",
    "    parser.add_argument(\"--epochs\", default=10, type=int)\n",
    "    parser.add_argument(\"--start_epoch\", default=0, type=int)\n",
    "    parser.add_argument(\"--steps_per_epoch\", default=500, type=int)\n",
    "    parser.add_argument(\"--lr\", default=0.0003, type=float)\n",
    "    parser.add_argument(\"--warmup_steps\", default=100, type=int)\n",
    "    parser.add_argument(\"--warmup_type\", default=\"linear\", type=str)\n",
    "    parser.add_argument(\"--beta1\", default=0.9, type=float)\n",
    "    parser.add_argument(\"--beta2\", default=0.95, type=float)\n",
    "    parser.add_argument(\"--batch_size\", default=1, type=int, help=\"batch size per device per step\")\n",
    "    parser.add_argument(\"--grad_accumulation_steps\", default=1, type=int)\n",
    "    parser.add_argument(\"--val_batch_size\", default=1, type=int)\n",
    "    parser.add_argument(\"--gradient_checkpointing\", action=\"store_true\", default=False)\n",
    "    \n",
    "    # Model Checkpoint or Evaluation strategies\n",
    "    parser.add_argument(\"--resume\", default=\"\", type=str)\n",
    "    parser.add_argument(\"--auto_resume\", action=\"store_true\", default=True)\n",
    "    parser.add_argument(\"--no_eval\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--eval_only\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--print_freq\", default=1, type=int)\n",
    "    parser.add_argument(\"--debug\", action=\"store_true\", default=False, help=\"for debugging, will not save model and monitor\")\n",
    "    return parser.parse_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7444373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args([\n",
    "    \"--eval_only\", \n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86a02d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args.global_rank = int(os.environ.get(\"RANK\", 0))\n",
    "args.local_rank = int(os.environ.get(\"LOCAL_RANK\", args.local_rank))\n",
    "args.world_size = int(os.environ.get(\"WORLD_SIZE\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d54e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.samples_per_epoch = args.batch_size    \\\n",
    "                * args.grad_accumulation_steps  \\\n",
    "                * args.steps_per_epoch  \\\n",
    "                * args.world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8dac492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Screenspot; Split: hf_test_full; # samples: 1272\n",
      "Loading 1 Validation Datasets\n"
     ]
    }
   ],
   "source": [
    "val_dataset = HybridDataset(\n",
    "    processor,\n",
    "    inference=True,\n",
    "    args=args\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=False,\n",
    "    sampler=None,\n",
    "    collate_fn=partial(\n",
    "        collate_fn,\n",
    "        processor=processor\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5ddfe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build deepspeed config and initialize deepspeed\n",
    "ds_config = {\n",
    "    \"train_micro_batch_size_per_gpu\": args.batch_size,\n",
    "    \"gradient_accumulation_steps\": args.grad_accumulation_steps,\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": args.lr,\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"betas\": (args.beta1, args.beta2),\n",
    "        },\n",
    "    },\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupDecayLR\",\n",
    "        \"params\": {\n",
    "            \"total_num_steps\": args.epochs * args.steps_per_epoch,\n",
    "            \"warmup_min_lr\": 0,\n",
    "            \"warmup_max_lr\": args.lr,\n",
    "            \"warmup_num_steps\": args.warmup_steps,\n",
    "            \"warmup_type\": args.warmup_type,\n",
    "        },\n",
    "    },\n",
    "    \"fp16\": {\n",
    "        \"enabled\": args.precision == \"fp16\",\n",
    "    },\n",
    "    \"bf16\": {\n",
    "        \"enabled\": args.precision == \"bf16\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bebf925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-05 16:33:42,627] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.13.1, git-hash=unknown, git-branch=unknown\n",
      "[2025-10-05 16:33:42,628] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2025-10-05 16:33:42,629] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2025-10-05 16:33:42,879] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/khanddorj/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/khanddorj/.cache/torch_extensions/py310_cu118/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load fused_adam op: 0.009548425674438477 seconds\n",
      "[2025-10-05 16:33:43,068] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2025-10-05 16:33:43,068] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2025-10-05 16:33:43,135] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
      "[2025-10-05 16:33:43,136] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module fused_adam...\n",
      "/home/khanddorj/Documents/code/ShowUI/.venv/lib/python3.10/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-05 16:33:43,318] [INFO] [utils.py:791:see_memory_usage] begin bf16_optimizer\n",
      "[2025-10-05 16:33:43,319] [INFO] [utils.py:792:see_memory_usage] MA 4.12 GB         Max_MA 4.12 GB         CA 4.43 GB         Max_CA 4 GB \n",
      "[2025-10-05 16:33:43,320] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 8.62 GB, percent = 55.5%\n",
      "[2025-10-05 16:33:43,550] [INFO] [utils.py:791:see_memory_usage] before initializing group 0\n",
      "[2025-10-05 16:33:43,552] [INFO] [utils.py:792:see_memory_usage] MA 4.12 GB         Max_MA 4.12 GB         CA 4.43 GB         Max_CA 4 GB \n",
      "[2025-10-05 16:33:43,555] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 8.51 GB, percent = 54.7%\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 8.23 GiB. GPU 0 has a total capacty of 11.92 GiB of which 3.05 GiB is free. Including non-PyTorch memory, this process has 8.46 GiB memory in use. Of the allocated memory 8.23 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Then initialize deepspeed\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_engine, optimizer, train_loader, scheduler \u001b[38;5;241m=\u001b[39m \u001b[43mdeepspeed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Fix: pass actual parameters\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/ShowUI/.venv/lib/python3.10/site-packages/deepspeed/__init__.py:171\u001b[0m, in \u001b[0;36minitialize\u001b[0;34m(args, model, optimizer, model_parameters, training_data, lr_scheduler, mpu, dist_init_required, collate_fn, config, config_params)\u001b[0m\n\u001b[1;32m    159\u001b[0m         engine \u001b[38;5;241m=\u001b[39m DeepSpeedHybridEngine(args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    160\u001b[0m                                        model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    161\u001b[0m                                        optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m                                        config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    169\u001b[0m                                        config_class\u001b[38;5;241m=\u001b[39mconfig_class)\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m         engine \u001b[38;5;241m=\u001b[39m \u001b[43mDeepSpeedEngine\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmodel_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdist_init_required\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist_init_required\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mconfig_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m mpu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmpu must be None with pipeline parallelism\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/code/ShowUI/.venv/lib/python3.10/site-packages/deepspeed/runtime/engine.py:308\u001b[0m, in \u001b[0;36mDeepSpeedEngine.__init__\u001b[0;34m(self, args, model, optimizer, model_parameters, training_data, lr_scheduler, mpu, dist_init_required, collate_fn, config, config_class, dont_change_device)\u001b[0m\n\u001b[1;32m    305\u001b[0m     model_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(model_parameters)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_optimizer:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_configure_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_lr_scheduler(lr_scheduler)\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_progress(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/code/ShowUI/.venv/lib/python3.10/site-packages/deepspeed/runtime/engine.py:1258\u001b[0m, in \u001b[0;36mDeepSpeedEngine._configure_optimizer\u001b[0;34m(self, client_optimizer, model_parameters)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fp16_optimizer(basic_optimizer)\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m optimizer_wrapper \u001b[38;5;241m==\u001b[39m BFLOAT16:\n\u001b[0;32m-> 1258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_configure_bf16_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasic_optimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m basic_optimizer\n",
      "File \u001b[0;32m~/Documents/code/ShowUI/.venv/lib/python3.10/site-packages/deepspeed/runtime/engine.py:1463\u001b[0m, in \u001b[0;36mDeepSpeedEngine._configure_bf16_optimizer\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m   1460\u001b[0m log_dist(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreating BF16 optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m, ranks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1462\u001b[0m timers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwall_clock_breakdown() \u001b[38;5;28;01melse\u001b[39;00m NoopTimer()\n\u001b[0;32m-> 1463\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mBF16_Optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mmpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mclip_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mallgather_bucket_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_allgather_bucket_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdp_process_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_data_parallel_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mtimers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mgrad_acc_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mgraph_harvesting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_harvesting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer\n",
      "File \u001b[0;32m~/Documents/code/ShowUI/.venv/lib/python3.10/site-packages/deepspeed/runtime/bf16_optimizer.py:87\u001b[0m, in \u001b[0;36mBF16_Optimizer.__init__\u001b[0;34m(self, init_optimizer, param_names, mpu, clip_grad, norm_type, allgather_bucket_size, dp_process_group, timers, grad_acc_dtype, graph_harvesting)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_harvesting \u001b[38;5;241m=\u001b[39m graph_harvesting\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musing_real_optimizer:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_for_real_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m see_memory_usage(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend bf16_optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/code/ShowUI/.venv/lib/python3.10/site-packages/deepspeed/runtime/bf16_optimizer.py:122\u001b[0m, in \u001b[0;36mBF16_Optimizer._setup_for_real_optimizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_partitioned_groups\u001b[38;5;241m.\u001b[39mappend(bf16_dp_partitions)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# create fp32 params partition\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp32_groups_flat_partition\u001b[38;5;241m.\u001b[39mappend(\u001b[43mbf16_dp_partitions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpartition_id\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp32_groups_flat_partition[i]\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    125\u001b[0m num_elem_list \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_groups[i]]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 8.23 GiB. GPU 0 has a total capacty of 11.92 GiB of which 3.05 GiB is free. Including non-PyTorch memory, this process has 8.46 GiB memory in use. Of the allocated memory 8.23 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "# Then initialize deepspeed\n",
    "model_engine, optimizer, train_loader, scheduler = deepspeed.initialize(\n",
    "    model=model,\n",
    "    model_parameters=model.parameters(),  # Fix: pass actual parameters\n",
    "    training_data=val_dataset,\n",
    "    collate_fn=partial(collate_fn, processor=processor),\n",
    "    config=ds_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bcc030",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_screenspot(\n",
    "    val_loader=val_loader,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f85425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
